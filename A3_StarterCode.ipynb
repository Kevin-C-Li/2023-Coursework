{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "id": "_hwFIUlFzTYw",
    "outputId": "9419a67b-5c1d-47e0-a7f5-ec9b9cad5bca"
   },
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "import warnings; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "id": "GWrZdqrp2E98"
   },
   "outputs": [],
   "source": [
    "emotions ={\n",
    "  '01':'neutral',\n",
    "  '02':'calm',\n",
    "  '03':'happy',\n",
    "  '04':'sad',\n",
    "  '05':'angry',\n",
    "  '06':'fearful',\n",
    "  '07':'disgust',\n",
    "  '08':'surprised'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrgQMSEU-nzZ"
   },
   "source": [
    "### Data for binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "id": "vSe0sBT12HgO"
   },
   "outputs": [],
   "source": [
    "def load_extract_features(data_path):\n",
    "\n",
    "    '''\n",
    "    load_extract_features() is a function that is used to load all the audio files one at a time, compute their features and return the features as well as the target values.\n",
    "\n",
    "    There are around 8-10 audio files which are corrupted. We hardcode zero values for such files in order to maintain consistency.\n",
    "\n",
    "    ['calm', 'happy'] emotion data is categorized into 'positive' and  ['angry', 'fearful'] into 'negative'\n",
    "\n",
    "    Returns:\n",
    "    1. Features\n",
    "    2. Binary Target Values\n",
    "    '''\n",
    "    final_features,target_emotions, binary_label = [],[], []\n",
    "    count = 0\n",
    "    \n",
    "    for i in glob.glob(data_path + \"/Actor_*/*.wav\"): #Loop to read every file.\n",
    "        \n",
    "        name = os.path.basename(i)\n",
    "        #We split the name of the file to understand the emotion associated with the file.\n",
    "        split = name.split(\"-\")\n",
    "        #We know that the third identifier is associated with the emotion of the audio file. Hence, we use [2] as it represents the third identifier.\n",
    "        emotion = emotions[split[2]]\n",
    "\n",
    "        #Below is the code to categorize the emotions into two classes to make this a binary problem.\n",
    "        if emotion in ['calm', 'happy']:\n",
    "            binary_label.append(0)\n",
    "        elif emotion in ['angry', 'fearful']:\n",
    "            binary_label.append(1)\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        with soundfile.SoundFile(i) as audio:\n",
    "            waveform = audio.read(dtype=\"float32\")\n",
    "            sr = audio.samplerate\n",
    "            \n",
    "            #Below is the code to extract the Mel spectrogram features\n",
    "            #128 is the standard for machine learning applications using Mel spectrograms\n",
    "            m_feature = librosa.feature.melspectrogram(y=waveform, sr=sr, n_mels=128, fmax=sr / 2.0).T\n",
    "            melspectrogram = np.mean(m_feature,axis=0)\n",
    "            if melspectrogram.shape != (128,):\n",
    "                melspectrogram = np.zeros(128)\n",
    "            \n",
    "            #Below is the code to extract the chromagram features\n",
    "            stft_wave = librosa.stft(waveform)\n",
    "            stft = np.abs(stft_wave)\n",
    "            c_feature = librosa.feature.chroma_stft(S=stft, sr=sr).T\n",
    "            chromagram = np.mean(c_feature,axis=0)\n",
    "            \n",
    "            #12 is the number of pitch classes\n",
    "            if chromagram.shape != (12,):\n",
    "                chromagram = np.zeros(12)\n",
    "                \n",
    "            features=np.array([])\n",
    "            features=np.hstack((chromagram, melspectrogram))\n",
    "        \n",
    "            final_features.append(features)\n",
    "            target_emotions.append(emotion)\n",
    "            \n",
    "            count += 1\n",
    "            if count % 100 == 0:\n",
    "                print(\"Processed Audio File Number: \", count)\n",
    "    \n",
    "    #We return the features and the binary target values.\n",
    "    return np.array(final_features), np.array(binary_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "id": "aER6S-_k2a9H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Audio File Number:  100\n",
      "Processed Audio File Number:  200\n",
      "Processed Audio File Number:  300\n",
      "Processed Audio File Number:  400\n",
      "Processed Audio File Number:  500\n",
      "Processed Audio File Number:  600\n",
      "Processed Audio File Number:  700\n"
     ]
    }
   ],
   "source": [
    "#Please change the path below to the path of the folder saved on your computer.\n",
    "data_path = './Audio_Speech_Actors_01-24'\n",
    "X, binary_label = load_extract_features(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aug = np.hstack((X, np.ones((np.shape(X)[0], 1))))\n",
    "binary_label[binary_label == 0] = -1\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_aug, binary_label, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "REG = 1 # regularization constant\n",
    "hinge = lambda x, y, weight : np.maximum(0, 1-(y * (weight @ x)))\n",
    "def hinge_sum(x, y, weight):\n",
    "    sum = 0.0\n",
    "    for i in range(np.shape(x)[0]):\n",
    "        sum += hinge(x[i], y[i], weight)\n",
    "    return (sum/np.shape(x)[0])\n",
    "cost = lambda weight : REG * 0.5 * np.dot(weight, weight) # weight cost function\n",
    "\n",
    "def compute_gradient(x, y, weight):\n",
    "    grad = np.zeros(np.shape(X_train)[1])\n",
    "    for i in range(np.shape(x)[0]):\n",
    "        if(abs(hinge(x[i], y[i], weight)) <= 0.0001):\n",
    "            grad += REG * weight\n",
    "        else:\n",
    "            grad += (REG * weight - y[i]*x[i])\n",
    "    return grad/np.shape(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVM(X_train, Y_train):\n",
    "    weight = np.zeros(np.shape(X_train)[1])\n",
    "    init_cost = hinge_sum(X_train, Y_train, weight) + cost(weight)\n",
    "    new_cost = -10000\n",
    "    GRAD_DESC_REG = 0.01 # Step size \n",
    "    i = 0\n",
    "    while(new_cost < init_cost-0.00001):\n",
    "        if i != 0:\n",
    "            init_cost = new_cost\n",
    "        grad = compute_gradient(X_train, Y_train, weight)\n",
    "        weight = weight - GRAD_DESC_REG * grad\n",
    "        new_cost = hinge_sum(X_train, Y_train, weight) + cost(weight)\n",
    "        i += 1\n",
    "    print(\"Gradient descent completed in\", i, \"iterations\")\n",
    "    return weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent completed in 76 iterations\n",
      "Accuracy of classifier on training data: 0.6629422718808193\n",
      "Accuracy of classifier on testing data: 0.6753246753246753\n"
     ]
    }
   ],
   "source": [
    "def predict(x, weight):\n",
    "    return -1 if (weight @ x <= 0) else 1\n",
    "\n",
    "weight = train_SVM(X_train, Y_train)\n",
    "train_error = 0\n",
    "for i in range(np.shape(X_train)[0]):\n",
    "    pred = predict(X_train[i], weight)\n",
    "    if pred != Y_train[i]:\n",
    "        train_error += 1\n",
    "\n",
    "print(\"Accuracy of classifier on training data:\", 1-(train_error/np.shape(X_train)[0]))\n",
    "\n",
    "test_error = 0\n",
    "for i in range(np.shape(X_test)[0]):\n",
    "    pred = predict(X_test[i], weight)\n",
    "    if pred != Y_test[i]:\n",
    "        test_error += 1\n",
    "\n",
    "print(\"Accuracy of classifier on testing data:\", 1-(test_error/np.shape(X_test)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of data reduced to (768, 24) while preserving approximately 99% of information\n"
     ]
    }
   ],
   "source": [
    "aver = np.mean(X, axis=0)\n",
    "cov_X = np.cov(X, rowvar=False)\n",
    "eig_val, eig_vec = np.linalg.eig(cov_X)\n",
    "ord = eig_val.argsort()[::-1]\n",
    "eig_val = eig_val[ord]\n",
    "eig_vec = eig_vec[:, ord]\n",
    "sum_eig = np.sum(eig_val)\n",
    "trans_mat = []\n",
    "total = 0\n",
    "i = 0\n",
    "while(total/sum_eig < 0.99):\n",
    "    trans_mat.append(eig_vec[:, i])\n",
    "    total += eig_val[i]\n",
    "    i += 1\n",
    "trans_mat = np.array(trans_mat)\n",
    "reduced_X = X @ trans_mat.T\n",
    "reduced_X = np.hstack((reduced_X, np.ones((np.shape(X)[0], 1))))\n",
    "print(\"Dimension of data reduced to\", np.shape(reduced_X), \n",
    "      \"while preserving approximately 99% of information\")\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    reduced_X, binary_label, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent completed in 30 iterations\n",
      "Accuracy of reduced classifier on training data: 0.7188081936685289\n",
      "Accuracy of reduced classifier on testing data: 0.7402597402597403\n"
     ]
    }
   ],
   "source": [
    "weight = train_SVM(X_train, Y_train)\n",
    "train_error = 0\n",
    "for i in range(np.shape(X_train)[0]):\n",
    "    pred = predict(X_train[i], weight)\n",
    "    if pred != Y_train[i]:\n",
    "        train_error += 1\n",
    "\n",
    "print(\"Accuracy of reduced classifier on training data:\", \n",
    "      1-(train_error/np.shape(X_train)[0]))\n",
    "\n",
    "test_error = 0\n",
    "for i in range(np.shape(X_test)[0]):\n",
    "    pred = predict(X_test[i], weight)\n",
    "    if pred != Y_test[i]:\n",
    "        test_error += 1\n",
    "\n",
    "print(\"Accuracy of reduced classifier on testing data:\", \n",
    "      1-(test_error/np.shape(X_test)[0]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f86e798ea2a6012f1c0b4e34d4c3a3f5524c8127c3bec897cc8d442a3c4c9a39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
